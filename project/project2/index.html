<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Ozioma Akahara" />
    
    <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
    <title>My Project 2</title>
    <meta name="generator" content="Hugo 0.83.1" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../../post/">BLOG</a></li>
        
        <li><a href="../../projects/">PROJECTS</a></li>
        
        <li><a href="../../resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../../project/project2/">My Project 2</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         January 1, 0001 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>The two data sets I used are “murder_2015_final” and “police_locals”.The “murder_2015_final” data set (m15f) contained five variables (two character and three numeric), and it had eighty-three observations. After tidying, the number of variables remained five (three character and two numerical), and it had a hundred and sixty-six observations. The “police_locals” data set (pl) contained eight variables (one character and seven numeric), and it had seventy-five observations. After tidying, it had four variables (two character and two numerical), and it had four hundred and fifty observations. The “police_local” data set was acquired using calculations based on the U.S. Census, and this data set was interesting to me because it was compiled in response to the racially driven Ferguson protests that occurred in Missouri; the creators of the data set reasoned that if Ferguson had a huge racial gap in its population it should also be reflected in the police force assuming that they were locals. This reasoning caused the creators to compile a data set questioning the living situations of police in major cities. The “murder_2015_final” data set was acquired from the FBI crime data, this data was interesting to me because I was curious to see if total murders (from murder_2015_final data) would have an effect on force size (from police_locals data). For both data sets, I noticed that there were several variables that could be grouped together under a column. So for the “pl” data set, I used “pivot_longer” to group the variables: all, white, non_white, black, hispanic and asian, under a new variable that I called “race” and I put their values in a new variable called “perc_in” which means the percentages of the police depending on race that are locals in their city; this new tidy data set was termed “pl_tidy”. Then for the “m15f” data set, I used “pivot_longer” to group the variables: murders_2014, murders_2015, under a new variable that I called “year” and I used the “separate function” to rename the observations in the column into “2014” and “2015”; this new tidy data set was termed “m15f_tidy”. I noticed after tidying this data set that the variable “year” was numeric, but I wanted it to be a character variable so I used ‘as.character’ to make it one. I performed an inner join on the tidy versions of the two data sets; I joined these data set by “city”. This resulted in eight variables and three hundred and twenty-four observations; the joined data set was termed “m_pl”.</p>
<pre class="r"><code>library(fivethirtyeight)</code></pre>
<pre><code>## Some larger datasets need to be installed separately, like senators and
## house_district_forecast. To install these, we recommend you install the
## fivethirtyeightdata package by running:
## install.packages(&#39;fivethirtyeightdata&#39;, repos =
## &#39;https://fivethirtyeightdata.github.io/drat/&#39;, type = &#39;source&#39;)</code></pre>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.3     ✓ purrr   0.3.4
## ✓ tibble  3.0.4     ✓ dplyr   1.0.2
## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
## ✓ readr   1.4.0     ✓ forcats 0.5.0</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>write_csv(murder_2015_final, &quot;m15f.csv&quot;)
getwd()</code></pre>
<pre><code>## [1] &quot;/stor/home/oaa847/website/content/project&quot;</code></pre>
<pre class="r"><code>m15f &lt;- read_csv(&quot;m15f.csv&quot;)</code></pre>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   city = col_character(),
##   state = col_character(),
##   murders_2014 = col_double(),
##   murders_2015 = col_double(),
##   change = col_double()
## )</code></pre>
<pre class="r"><code>str(m15f)</code></pre>
<pre><code>## tibble [83 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ city        : chr [1:83] &quot;Baltimore&quot; &quot;Chicago&quot; &quot;Houston&quot; &quot;Cleveland&quot; ...
##  $ state       : chr [1:83] &quot;Maryland&quot; &quot;Illinois&quot; &quot;Texas&quot; &quot;Ohio&quot; ...
##  $ murders_2014: num [1:83] 211 411 242 63 105 90 248 78 41 159 ...
##  $ murders_2015: num [1:83] 344 478 303 120 162 145 280 109 72 188 ...
##  $ change      : num [1:83] 133 67 61 57 57 55 32 31 31 29 ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   city = col_character(),
##   ..   state = col_character(),
##   ..   murders_2014 = col_double(),
##   ..   murders_2015 = col_double(),
##   ..   change = col_double()
##   .. )</code></pre>
<pre class="r"><code>write_csv(police_locals, &quot;pl.csv&quot;)
getwd()</code></pre>
<pre><code>## [1] &quot;/stor/home/oaa847/website/content/project&quot;</code></pre>
<pre class="r"><code>pl &lt;- read_csv(&quot;pl.csv&quot;)</code></pre>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   city = col_character(),
##   force_size = col_double(),
##   all = col_double(),
##   white = col_double(),
##   non_white = col_double(),
##   black = col_double(),
##   hispanic = col_double(),
##   asian = col_double()
## )</code></pre>
<pre class="r"><code>str(pl)</code></pre>
<pre><code>## tibble [75 × 8] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ city      : chr [1:75] &quot;New York&quot; &quot;Chicago&quot; &quot;Los Angeles&quot; &quot;Washington&quot; ...
##  $ force_size: num [1:75] 32300 12120 10100 9340 7700 ...
##  $ all       : num [1:75] 0.618 0.875 0.228 0.116 0.292 ...
##  $ white     : num [1:75] 0.4464 0.872 0.1528 0.0568 0.1737 ...
##  $ non_white : num [1:75] 0.764 0.877 0.264 0.157 0.399 ...
##  $ black     : num [1:75] 0.771 0.897 0.387 0.17 0.366 ...
##  $ hispanic  : num [1:75] 0.7629 0.8398 0.2177 0.0899 0.4571 ...
##  $ asian     : num [1:75] 0.749 0.967 0.305 0.231 0.408 ...
##  - attr(*, &quot;spec&quot;)=
##   .. cols(
##   ..   city = col_character(),
##   ..   force_size = col_double(),
##   ..   all = col_double(),
##   ..   white = col_double(),
##   ..   non_white = col_double(),
##   ..   black = col_double(),
##   ..   hispanic = col_double(),
##   ..   asian = col_double()
##   .. )</code></pre>
<pre class="r"><code>pl_tidy &lt;- pl %&gt;% pivot_longer(all:asian, names_to = &quot;race&quot;, values_to = &quot;perc_in&quot;)
str(pl_tidy)</code></pre>
<pre><code>## tibble [450 × 4] (S3: tbl_df/tbl/data.frame)
##  $ city      : chr [1:450] &quot;New York&quot; &quot;New York&quot; &quot;New York&quot; &quot;New York&quot; ...
##  $ force_size: num [1:450] 32300 32300 32300 32300 32300 ...
##  $ race      : chr [1:450] &quot;all&quot; &quot;white&quot; &quot;non_white&quot; &quot;black&quot; ...
##  $ perc_in   : num [1:450] 0.618 0.446 0.764 0.771 0.763 ...</code></pre>
<pre class="r"><code>m15f_tidy &lt;- m15f %&gt;% pivot_longer(3:4, names_to = &quot;years&quot;, values_to = &quot;total_murders&quot;) %&gt;% separate(years,into = c(NA,&quot;year&quot;), sep=8, convert=T)
m15f_tidy$year &lt;- as.character(m15f_tidy$year)
str(m15f_tidy)</code></pre>
<pre><code>## tibble [166 × 5] (S3: tbl_df/tbl/data.frame)
##  $ city         : chr [1:166] &quot;Baltimore&quot; &quot;Baltimore&quot; &quot;Chicago&quot; &quot;Chicago&quot; ...
##  $ state        : chr [1:166] &quot;Maryland&quot; &quot;Maryland&quot; &quot;Illinois&quot; &quot;Illinois&quot; ...
##  $ change       : num [1:166] 133 133 67 67 61 61 57 57 57 57 ...
##  $ year         : chr [1:166] &quot;2014&quot; &quot;2015&quot; &quot;2014&quot; &quot;2015&quot; ...
##  $ total_murders: num [1:166] 211 344 411 478 242 303 63 120 105 162 ...</code></pre>
<pre class="r"><code>m15f_tidy %&gt;% inner_join(pl_tidy, by = &quot;city&quot;)-&gt;m_pl
str(m_pl)</code></pre>
<pre><code>## tibble [324 × 8] (S3: tbl_df/tbl/data.frame)
##  $ city         : chr [1:324] &quot;Baltimore&quot; &quot;Baltimore&quot; &quot;Baltimore&quot; &quot;Baltimore&quot; ...
##  $ state        : chr [1:324] &quot;Maryland&quot; &quot;Maryland&quot; &quot;Maryland&quot; &quot;Maryland&quot; ...
##  $ change       : num [1:324] 133 133 133 133 133 133 133 133 133 133 ...
##  $ year         : chr [1:324] &quot;2014&quot; &quot;2014&quot; &quot;2014&quot; &quot;2014&quot; ...
##  $ total_murders: num [1:324] 211 211 211 211 211 211 344 344 344 344 ...
##  $ force_size   : num [1:324] 2800 2800 2800 2800 2800 2800 2800 2800 2800 2800 ...
##  $ race         : chr [1:324] &quot;all&quot; &quot;white&quot; &quot;non_white&quot; &quot;black&quot; ...
##  $ perc_in      : num [1:324] 0.257 0.133 0.362 0.391 NA ...</code></pre>
<pre class="r"><code>sapply(m_pl, mode)</code></pre>
<pre><code>##          city         state        change          year total_murders 
##   &quot;character&quot;   &quot;character&quot;     &quot;numeric&quot;   &quot;character&quot;     &quot;numeric&quot; 
##    force_size          race       perc_in 
##     &quot;numeric&quot;   &quot;character&quot;     &quot;numeric&quot;</code></pre>
<pre class="r"><code>m_pl %&gt;% distinct(state)</code></pre>
<pre><code>## # A tibble: 21 x 1
##    state       
##    &lt;chr&gt;       
##  1 Maryland    
##  2 Illinois    
##  3 Texas       
##  4 Ohio        
##  5 D.C.        
##  6 Wisconsin   
##  7 Pennsylvania
##  8 Missouri    
##  9 Colorado    
## 10 California  
## # … with 11 more rows</code></pre>
</div>
<div id="manova-test" class="section level2">
<h2>MANOVA Test</h2>
<p>Using the dataset, I computed a MANOVA testing whether at least one of the four response variables (change, total_murders, force_size, perc_in) differs by race. I checked some assumptions, the multivariate normality and homogeneity, and found that normality and homogeneity were likely not met, as all the races had significant p-values and the correlation values were strange. However, the MANOVA test revealed that there was no significant mean difference across the different races (p=0.09003). Despite that, I still ran an ANOVA and found that force_size (p=0.01894) and perc_in (p=0.01215) were the significant response variables. So I ran a post-hoc test for both of these variables, it was a pairwise t-test. In all I ran 1 MANOVA, 4 ANOVAs, and 10 pairwise t-tests, so alpha = 0.003333333, which was still significant.Across this whole set of tests, the probability that I made at least one type I error is 0.5367088.The significance level needed to keep the overall type I error rate at .05 is 0.003333333.*</p>
<pre class="r"><code>library(dplyr)

library(rstatix)</code></pre>
<pre><code>## 
## Attaching package: &#39;rstatix&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre class="r"><code>group &lt;- m_pl$race 
DVs &lt;- m_pl %&gt;% select(change, total_murders, force_size, perc_in)
sapply(split(DVs,group), mshapiro_test)</code></pre>
<pre><code>##           all          asian       black        hispanic     non_white   
## statistic 0.5616121    0.7561      0.5634962    0.5123676    0.5553382   
## p.value   1.881222e-11 0.001502922 3.389959e-11 4.542103e-10 1.530722e-11
##           white       
## statistic 0.5641287   
## p.value   2.044592e-11</code></pre>
<pre class="r"><code>lapply(split(DVs,group), cov) </code></pre>
<pre><code>## $all
##                     change total_murders   force_size      perc_in
## change        1.031497e+03    1778.54507 3.042159e+04   0.84813665
## total_murders 1.778545e+03   12165.88015 4.124840e+05  10.48327276
## force_size    3.042159e+04  412483.97624 3.829295e+07 308.35059257
## perc_in       8.481366e-01      10.48327 3.083506e+02   0.05340024
## 
## $asian
##                  change total_murders  force_size perc_in
## change         1031.497      1778.545    30421.59      NA
## total_murders  1778.545     12165.880   412483.98      NA
## force_size    30421.593    412483.976 38292952.90      NA
## perc_in              NA            NA          NA      NA
## 
## $black
##                  change total_murders  force_size perc_in
## change         1031.497      1778.545    30421.59      NA
## total_murders  1778.545     12165.880   412483.98      NA
## force_size    30421.593    412483.976 38292952.90      NA
## perc_in              NA            NA          NA      NA
## 
## $hispanic
##                  change total_murders  force_size perc_in
## change         1031.497      1778.545    30421.59      NA
## total_murders  1778.545     12165.880   412483.98      NA
## force_size    30421.593    412483.976 38292952.90      NA
## perc_in              NA            NA          NA      NA
## 
## $non_white
##                     change total_murders   force_size      perc_in
## change         1031.496855    1778.54507 3.042159e+04   1.25995105
## total_murders  1778.545073   12165.88015 4.124840e+05  10.58501240
## force_size    30421.593291  412483.97624 3.829295e+07 364.95875279
## perc_in           1.259951      10.58501 3.649588e+02   0.05269563
## 
## $white
##                     change total_murders   force_size      perc_in
## change        1.031497e+03  1.778545e+03 3.042159e+04   0.57947462
## total_murders 1.778545e+03  1.216588e+04 4.124840e+05   7.45203862
## force_size    3.042159e+04  4.124840e+05 3.829295e+07 190.26665639
## perc_in       5.794746e-01  7.452039e+00 1.902667e+02   0.05926163</code></pre>
<pre class="r"><code>man1&lt;-manova(cbind(change, total_murders, force_size, perc_in)~race, data=m_pl)
summary(man1)</code></pre>
<pre><code>##            Df  Pillai approx F num Df den Df  Pr(&gt;F)  
## race        5 0.10865   1.4519     20   1040 0.09003 .
## Residuals 260                                         
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(aov(man1))</code></pre>
<pre><code>##  Response change :
##              Df Sum Sq Mean Sq F value Pr(&gt;F)
## race          5   2096  419.18  0.4311 0.8268
## Residuals   260 252824  972.40               
## 
##  Response total_murders :
##              Df  Sum Sq Mean Sq F value Pr(&gt;F)
## race          5   70610   14122  1.0852 0.3689
## Residuals   260 3383538   13014               
## 
##  Response force_size :
##              Df     Sum Sq   Mean Sq F value  Pr(&gt;F)  
## race          5 5.8652e+08 117303880    2.76 0.01894 *
## Residuals   260 1.1051e+10  42501994                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response perc_in :
##              Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  
## race          5  0.9079 0.181575  2.9888 0.01215 *
## Residuals   260 15.7956 0.060752                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## 58 observations deleted due to missingness</code></pre>
<pre class="r"><code>pairwise.t.test(m_pl$force_size,m_pl$race,p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  m_pl$force_size and m_pl$race 
## 
##           all asian black hispanic non_white
## asian     1   -     -     -        -        
## black     1   1     -     -        -        
## hispanic  1   1     1     -        -        
## non_white 1   1     1     1        -        
## white     1   1     1     1        1        
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(m_pl$perc_in,m_pl$race,p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  m_pl$perc_in and m_pl$race 
## 
##           all    asian  black  hispanic non_white
## asian     0.1035 -      -      -        -        
## black     0.0556 0.6992 -      -        -        
## hispanic  0.2908 0.3958 0.4843 -        -        
## non_white 0.1825 0.4383 0.5498 0.8758   -        
## white     0.1898 0.0139 0.0014 0.0251   0.0085   
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>0.05/15</code></pre>
<pre><code>## [1] 0.003333333</code></pre>
<pre class="r"><code>#prob. of getting at least one type 1 error
##prob of not getting a type 1 error = .95
##prob of not getting a type 1 error 15 times 
.95^15</code></pre>
<pre><code>## [1] 0.4632912</code></pre>
<pre class="r"><code>##prob of getting at least one type 1 error:
1- (0.4632912)</code></pre>
<pre><code>## [1] 0.5367088</code></pre>
</div>
<div id="randomization-test" class="section level2">
<h2>Randomization Test</h2>
<p>I performed a randomization test on my data that calculates the F-statistic 5000 times and finds the sampling distribution of F. The null hypothesis is that all the states have the same mean in force size, while the alternative hypothesis that the mean of force size is different among the states. The p-value from the randomization test is 0, meaning than none of the 5000 F-statistics generated under the null hypothesis were higher than the actual F-statistic. Therefore, I rejected the null hypothesis and concluded that the groups differ.</p>
<pre class="r"><code>library(dplyr)
summary(aov(force_size~state,data=m_pl))</code></pre>
<pre><code>##              Df    Sum Sq   Mean Sq F value Pr(&gt;F)    
## state        20 1.155e+10 577258814   276.8 &lt;2e-16 ***
## Residuals   303 6.320e+08   2085752                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>obs_F &lt;- 276.8#this is our observed F-statistic


SSW&lt;- m_pl%&gt;%group_by(state)%&gt;%summarize(SSW=sum((force_size-mean(force_size))^2))%&gt;%summarize(sum(SSW))%&gt;%pull</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code>SSB&lt;- m_pl%&gt;%mutate(mean=mean(force_size))%&gt;%group_by(state)%&gt;%mutate(groupmean=mean(force_size))%&gt;% summarize(SSB=sum((mean-groupmean)^2))%&gt;%summarize(sum(SSB))%&gt;%pull</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code>SSB</code></pre>
<pre><code>## [1] 11545176272</code></pre>
<pre class="r"><code>SSW</code></pre>
<pre><code>## [1] 631982750</code></pre>
<pre class="r"><code>Fs&lt;-(SSB/20)/(SSW/303)
Fs</code></pre>
<pre><code>## [1] 276.763</code></pre>
<pre class="r"><code>pf(Fs,df1=2, df2=27, lower.tail=F )</code></pre>
<pre><code>## [1] 1.027588e-18</code></pre>
<pre class="r"><code>plot(curve(df(x, 2,27)), type=&quot;line&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre><code>## Warning in plot.xy(xy, type, ...): plot type &#39;line&#39; will be truncated to first
## character</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-3-2.png" width="672" /></p>
<pre class="r"><code>mean(Fs&gt;obs_F)</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
<div id="linear-regression-model" class="section level2">
<h2>Linear Regression Model</h2>
<p>I built a linear regression model predicting force size from total murders and year with their interaction. Since total_murders was my only numeric variable, I mean-centered it. 5088.90 is the mean/predicted force size for 2014 with average total murders. For forces with average total murders, 2015 had average/predicted force size that is 749.66 lower than 2014, the difference is not significant. Total murders was significantly associated with force size for 2014: for every 1-unit increase in total murder, predicted force size goes up by 34.25. I made a plot to test homoskedasticity, and found that the points fan out slightly, so my null hypothesis might have been met; but the assumptions of normality and linearity are not met. To test it more, I ran a Breuch-Pagan Test and found that it was significant (p=5.941e-13), therefore I rejected the null hypothesis of homoskedasticity and redid the regression using heteroskedasticity robust standard errors and found that t-statistic for total murders is now 8.302684, compared to the previous value of 13.7, while that of 2015 is now -1.35832 compared to -1.371999, and the p-values are now larger. 36.9% of the variation in the outcome is explained by this model.</p>
<pre class="r"><code>library(lmtest)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>library(sandwich)
library(tidyverse)
library(ggplot2)
m_pl$total_murders_c &lt;- m_pl$total_murders - mean( m_pl$total_murders, na.rm = T)
fit&lt;-lm(force_size ~ year + total_murders_c, data=m_pl)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = force_size ~ year + total_murders_c, data = m_pl)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8275.4 -2300.0  -378.0   714.7 20950.6 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      5088.90     385.39  13.204   &lt;2e-16 ***
## year2015         -749.66     546.40  -1.372    0.171    
## total_murders_c    34.25       2.50  13.699   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4893 on 321 degrees of freedom
## Multiple R-squared:  0.3689, Adjusted R-squared:  0.365 
## F-statistic: 93.83 on 2 and 321 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>ggplot(m_pl, aes(x=total_murders_c, y=force_size,group=year))+geom_point(aes(color=year))+  geom_smooth(method=&quot;lm&quot;,formula=y~1,se=F,fullrange=T,aes(color=year))+theme(legend.position=c(.9,.19))</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>plot(m_pl$total_murders_c,m_pl$force_size)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<pre class="r"><code>bptest(fit)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit
## BP = 56.303, df = 2, p-value = 5.941e-13</code></pre>
<pre class="r"><code>coeftest(fit, vcov = vcovHC(fit))[,1:2]</code></pre>
<pre><code>##                   Estimate Std. Error
## (Intercept)     5088.90538 408.532537
## year2015        -749.66261 551.904255
## total_murders_c   34.24855   4.124997</code></pre>
<pre class="r"><code>#new t-statistic (Estimate/Standard error)
34.24855/ 4.1249974</code></pre>
<pre><code>## [1] 8.302684</code></pre>
<pre class="r"><code>-749.66261/551.904255</code></pre>
<pre><code>## [1] -1.35832</code></pre>
<pre class="r"><code>#old t-stat
34.25/2.50</code></pre>
<pre><code>## [1] 13.7</code></pre>
<pre class="r"><code>-749.66/546.40</code></pre>
<pre><code>## [1] -1.371999</code></pre>
<pre class="r"><code>summary(fit)$r.sq</code></pre>
<pre><code>## [1] 0.3689184</code></pre>
</div>
<div id="linear-regression-model-with-interaction" class="section level2">
<h2>Linear Regression Model with Interaction</h2>
<p>I built a linear regression model predicting force size from total murders and year with their interaction. Since total_murders was my only numeric variable, I mean-centered it.5137.631 is the mean/predicted force size for 2014 with average total murders. For forces with average total murders, 2015 had average/predicted force size that is 762.202 lower than 2014, the difference is not significant. Total murders was significantly associated with force size for 2014: for every 1-unit increase in total murder, predicted force size goes up by 38.701. Slope of total murders on force size for 2015 is 7.758 lower than for 2014 (not significant). After bootstrapping, the SEs for total murders (SE=3.756809) was in between the original SEs and the robust SEs from the previous section and the SEs for 2015 (SE=542.3384 ) was lower than the original and robust SEs.Their t-statistics are probably larger and their p-values are probably smaller, making the slope likely significant.</p>
<pre class="r"><code>library(lmtest)
library(sandwich)
fit1&lt;-lm(force_size ~ total_murders_c * year, data=m_pl)
summary(fit1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = force_size ~ total_murders_c * year, data = m_pl)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7704.2 -2436.0  -370.5  1002.3 21591.2 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)              5137.631    385.879  13.314   &lt;2e-16 ***
## total_murders_c            38.701      3.822  10.127   &lt;2e-16 ***
## year2015                 -762.202    545.302  -1.398    0.163    
## total_murders_c:year2015   -7.758      5.045  -1.538    0.125    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4882 on 320 degrees of freedom
## Multiple R-squared:  0.3735, Adjusted R-squared:  0.3677 
## F-statistic:  63.6 on 3 and 320 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>resids&lt;-fit1$residuals #using model fit from 1.2 
fitted&lt;-fit1$fitted.values  

resid_resamp&lt;-replicate(5000,{    new_resids&lt;-sample(resids,replace=TRUE)     
m_pl$new_force_size&lt;-fitted+new_resids     
fit3&lt;-lm(new_force_size~total_murders_c * year,data=m_pl)    
coef(fit3) })
resid_resamp%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) total_murders_c year2015 total_murders_c:year2015
## 1    386.1523        3.837022   550.68                 5.034221</code></pre>
<p>###Logistic Regression Model
I fitted a logistic regression model predicting a whiteness as a race from force size and total murders. I wanted to use perc_in as a variable but the observations were not equal in number across the variables in the classification diagnostics so I stuck with total_murders. Controlling for total murders, there is no significant effect of force size on whether a cop is white. Also, controlling for force size, there is no significant effect of total murders on whether a cop is white. The odds ratio for force size on whiteness is 1.0000. The odds ratio for total murders on whiteness is 1.0000. This means that there is no association between whiteness and force size or total murders in a city.The accuracy is 0.8333333. The sensitivity is 0. The specificity is 0.8333333. The AUC is 0.5, which is bad; this also means that the True Positive Rate is equal to the False Positive Rate.</p>
<pre class="r"><code>library(tidyverse)
library(lmtest)
library(plotROC)
data&lt;-m_pl%&gt;%mutate(y=ifelse(race==&quot;white&quot;,1,0)) 

head(data)</code></pre>
<pre><code>## # A tibble: 6 x 10
##   city  state change year  total_murders force_size race  perc_in
##   &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;
## 1 Balt… Mary…    133 2014            211       2800 all     0.257
## 2 Balt… Mary…    133 2014            211       2800 white   0.133
## 3 Balt… Mary…    133 2014            211       2800 non_…   0.362
## 4 Balt… Mary…    133 2014            211       2800 black   0.391
## 5 Balt… Mary…    133 2014            211       2800 hisp…  NA    
## 6 Balt… Mary…    133 2014            211       2800 asian  NA    
## # … with 2 more variables: total_murders_c &lt;dbl&gt;, y &lt;dbl&gt;</code></pre>
<pre class="r"><code>fit4&lt;-glm(y~force_size+total_murders_c,data=data, family=&quot;binomial&quot;)

coeftest(fit4)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                    Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)     -1.6094e+00  2.0717e-01 -7.7686 7.935e-15 ***
## force_size      -2.2044e-20  3.0519e-05  0.0000         1    
## total_murders_c  1.2071e-17  1.7122e-03  0.0000         1    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coeftest(fit4))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                 Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept)       0.2000     1.2302   4e-04    1.000
## force_size        1.0000     1.0000   1e+00    2.718
## total_murders_c   1.0000     1.0017   1e+00    2.718</code></pre>
<pre class="r"><code>probs &lt;- predict(fit4, type=&quot;response&quot;)

table(predict=as.numeric(probs&gt;.5), truth=data$y) %&gt;% addmargins</code></pre>
<pre><code>##        truth
## predict   0   1 Sum
##     0   270  54 324
##     Sum 270  54 324</code></pre>
<pre class="r"><code>#accuracy 
270/324</code></pre>
<pre><code>## [1] 0.8333333</code></pre>
<pre class="r"><code>#sensitivity
0/54</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>#specificity
270/324</code></pre>
<pre><code>## [1] 0.8333333</code></pre>
<pre class="r"><code>ROCplot1&lt;-ggplot(data)+geom_roc(aes(d=y,m=probs), n.cuts=0) 

ROCplot1</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>calc_auc(ROCplot1)</code></pre>
<pre><code>##   PANEL group AUC
## 1     1    -1 0.5</code></pre>
<pre class="r"><code>data -&gt; data1
data1$logit&lt;-predict(fit4,type=&quot;link&quot;) 
data1$y&lt;-as.factor(data$y)

data1%&gt;%ggplot()+geom_density(aes(logit,color=y,fill=y), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=-1.6)+xlab(&quot;predictor (logit)&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<p>###Logistic Regression Model with All Variables</p>
<p>I performed a logistic regression predicting whiteness from all of the rest of my variables. The in-sample classification diagnostics are: The model had an accuracy of 0.8796992, a sensitivity of 0.4814815, a specificity of 0.9811321, a precision of 0.8666667, and an AUC of 0.8238994. It has a relatively high accuracy which means it is good at selecting race, however its sensitivity is low which means it’s not so good in picking the correct race (white), on the other hand its specificity is really high which means it is good at picking the wrong race (all other race but white), and its AUC is relatively good but this is probably due to the high specificity.</p>
<pre class="r"><code>class_diag&lt;-function(probs,truth){
  
  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  prediction&lt;-ifelse(probs&gt;.5,1,0)
  acc=mean(truth==prediction)
  sens=mean(prediction[truth==1]==1)
  spec=mean(prediction[truth==0]==0)
  ppv=mean(truth[prediction==1]==1)
  f1=2*(sens*ppv)/(sens+ppv)
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}

data %&gt;% select( -total_murders_c, -race)-&gt; data
data %&gt;% na.omit() -&gt; data
fit5&lt;-glm(y~., data=data, family=&quot;binomial&quot;)

probs1&lt;-predict(fit5, type = &quot;response&quot;)
class_diag(probs1, data$y)</code></pre>
<pre><code>##         acc      sens      spec       ppv       auc
## 1 0.8796992 0.4814815 0.9811321 0.8666667 0.8238994</code></pre>
<p>This 10-fold CV model had an accuracy of 0.7866097, and compared to the previous model that had 0.8796992 it is less accurate. It had a sensitivity of 0.2740079, and compared to the previous model that had 0.4814815 it is less sensitive. It had a specificity of 0.9203602, and compared to the previous model that had 0.9811321 it is slightly less specific. It had a precision of 0.4366667, and compared to the previous model that has 0.8666667 it is less precise. It had an AUC of 0.6681949, and compared to the previous model that had 0.8238994, this AUC is poor.</p>
<pre class="r"><code>#10-fold CV
library(tidyverse)
k=10

data1 &lt;-  data%&gt;% sample_frac #put rows of dataset in random order
folds &lt;- ntile(1:nrow(data),n=10) #create fold labels

diags&lt;-NULL
for(i in 1:k){
  train &lt;- data1[folds!=i,] #create training set (all but fold i)
  test &lt;- data1[folds==i,] #create test set (just fold i)
  truth &lt;- test$y #save truth labels from fold i
  
  fit6 &lt;- glm(y~., data=train, family=&quot;binomial&quot;)
  probs2 &lt;- predict(fit6, newdata=test, type=&quot;response&quot;)
  
  diags&lt;-rbind(diags,class_diag(probs2,truth))
}</code></pre>
<pre><code>## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading

## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :
## prediction from a rank-deficient fit may be misleading</code></pre>
<pre class="r"><code>summarize_all(diags,mean)</code></pre>
<pre><code>##         acc      sens     spec ppv       auc
## 1 0.7742165 0.2883333 0.915425 NaN 0.5798501</code></pre>
<p>The only variable retained after performing a LASSO on the model is Baltimore city. Then I ran a classification diagnostic on this new model and found: It had an accuracy of 0.7969925, and compared to the in-sample model that had 0.8796992 it is less accurate. It had a sensitivity of 0, and compared to the in-sample model that had 0.4814815 it is not sensitive at all. It had a specificity of 1, and compared to the in-sample model that had 0.9811321 it is more specific. It had no precision, and compared to the in-sample model that has 0.8666667. It had an AUC of 0.5043676, and compared to the in-sample model that had 0.8238994, this AUC is bad. Compared to the logistic regression from the 10-fold CV, it is also lacking in sensitivity, precision and AUC, but it was better in accuracy and specificity.</p>
<pre class="r"><code>#Lasso

library(glmnet)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Loaded glmnet 4.0-2</code></pre>
<pre class="r"><code>y&lt;-as.matrix(data$y) 
x&lt;-model.matrix(fit5)[,-1] #grab predictors
cv&lt;-cv.glmnet(x,y,family=&quot;binomial&quot;)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 52 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                           s0
## (Intercept)        -1.367602
## cityBaltimore       0.000000
## cityBoston          .       
## cityChicago         .       
## cityCincinnati      .       
## cityCleveland       .       
## cityDallas          .       
## cityDenver          .       
## cityDetroit         .       
## cityHouston         .       
## cityIndianapolis    .       
## cityLas Vegas       .       
## cityLos Angeles     .       
## cityMiami           .       
## cityMilwaukee       .       
## cityMinneapolis     .       
## cityNew Orleans     .       
## cityNew York        .       
## cityPhiladelphia    .       
## cityPhoenix         .       
## cityPittsburgh      .       
## citySan Antonio     .       
## citySan Diego       .       
## citySan Francisco   .       
## citySeattle         .       
## citySt. Louis       .       
## cityWashington      .       
## stateCalifornia     .       
## stateColorado       .       
## stateD.C.           .       
## stateFlorida        .       
## stateGeorgia        .       
## stateIllinois       .       
## stateIndiana        .       
## stateLouisiana      .       
## stateMaryland       .       
## stateMassachusetts  .       
## stateMichigan       .       
## stateMinnesota      .       
## stateMissouri       .       
## stateNevada         .       
## stateNew York       .       
## stateOhio           .       
## statePennsylvania   .       
## stateTexas          .       
## stateWashington     .       
## stateWisconsin      .       
## change              .       
## year2015            .       
## total_murders       .       
## force_size          .       
## perc_in             .</code></pre>
<pre class="r"><code>lasso_dat &lt;- data %&gt;% mutate( Baltimore= ifelse(city==&quot;Baltimore&quot;, 1, 0)) %&gt;% select(Baltimore, y )

fit7&lt;-glm(y~.,data=lasso_dat, family=&quot;binomial&quot;) 
probs3&lt;-predict(fit7, type = &quot;response&quot;)
class_diag(probs3, lasso_dat$y)</code></pre>
<pre><code>##         acc sens spec ppv       auc
## 1 0.7969925    0    1 NaN 0.5043676</code></pre>
<pre class="r"><code>table(predict=as.numeric(probs3&gt;.5),truth=lasso_dat$y)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict   0   1 Sum
##     0   212  54 266
##     Sum 212  54 266</code></pre>
<pre class="r"><code>library(tidyverse)
k=10
data1 &lt;- lasso_dat %&gt;% sample_frac 
folds &lt;- ntile(1:nrow(data),n=10) 

diags&lt;-NULL
for(i in 1:k){  
  train &lt;- data1[folds!=i,]   
  test &lt;- data1[folds==i,]  
  truth &lt;- test$y 
  
  fit8 &lt;- glm(y~., 
             data=train, family=&quot;binomial&quot;)
  probs4 &lt;- predict(fit8, newdata=test, type=&quot;response&quot;)
  
  diags&lt;-rbind(diags,class_diag(probs4,truth))
}



summarize_all(diags,mean)</code></pre>
<pre><code>##        acc sens spec ppv       auc
## 1 0.797151    0    1 NaN 0.4739618</code></pre>
</div>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../../js/docs.min.js"></script>
<script src="../../js/main.js"></script>

<script src="../../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
